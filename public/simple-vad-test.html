<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>VAD Tuner - Simplified Documentation Pattern</title>
    <style>
        body { font-family: Arial, sans-serif; padding: 20px; max-width: 1200px; margin: 0 auto; }
        .result { background: #f0f0f0; padding: 10px; margin: 10px 0; font-family: monospace; white-space: pre-wrap; }
        .success { background: #d4edda; }
        .error { background: #f8d7da; }
        .warning { background: #fff3cd; }
        
        .controls-section {
            margin: 20px 0;
            padding: 20px;
            border: 2px solid #007bff;
            border-radius: 12px;
            background: #f8f9fa;
        }
        .controls-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 15px;
            margin: 15px 0;
        }
        .control-group {
            display: flex;
            flex-direction: column;
            gap: 5px;
        }
        .control-group label {
            font-weight: bold;
            color: #495057;
            font-size: 14px;
        }
        .control-group input[type="range"] {
            width: 100%;
            margin: 5px 0;
        }
        .control-group span {
            font-family: monospace;
            font-weight: bold;
            color: #007bff;
            text-align: center;
            background: white;
            padding: 2px 8px;
            border-radius: 4px;
            border: 1px solid #dee2e6;
        }
        .control-buttons {
            display: flex;
            gap: 10px;
            margin-top: 20px;
            flex-wrap: wrap;
        }
        .primary-btn {
            background: #28a745;
            color: white;
            border: none;
            padding: 12px 24px;
            border-radius: 6px;
            font-weight: bold;
            cursor: pointer;
            font-size: 16px;
        }
        .primary-btn:hover { background: #218838; }
        .secondary-btn {
            background: #6c757d;
            color: white;
            border: none;
            padding: 12px 24px;
            border-radius: 6px;
            font-weight: bold;
            cursor: pointer;
        }
        .secondary-btn:hover { background: #545b62; }
        .preset-btn {
            background: #17a2b8;
            color: white;
            border: none;
            padding: 10px 16px;
            border-radius: 6px;
            cursor: pointer;
            font-size: 14px;
        }
        .preset-btn:hover { background: #138496; }
        
        .audio-section {
            margin: 20px 0;
            padding: 15px;
            border: 1px solid #ddd;
            border-radius: 8px;
            background: #f9f9f9;
        }
        #waveform, #spectrogram {
            margin: 10px 0;
            border: 1px solid #ccc;
            border-radius: 4px;
            position: relative;
        }
        .vad-marker {
            position: absolute;
            top: 0;
            bottom: 0;
            border-left: 2px solid #ff0000;
            pointer-events: none;
            z-index: 10;
        }
        .vad-marker.start {
            border-left: 3px solid #00ff00;
        }
        .vad-marker.end {
            border-left: 3px solid #ff0000;
        }
        .vad-region {
            position: absolute;
            top: 0;
            bottom: 0;
            background: rgba(255, 255, 0, 0.2);
            pointer-events: none;
            z-index: 5;
            border: 1px solid rgba(255, 255, 0, 0.6);
        }
        .marker-label {
            position: absolute;
            top: -20px;
            font-size: 10px;
            color: #333;
            background: rgba(255, 255, 255, 0.8);
            padding: 1px 3px;
            border-radius: 2px;
            white-space: nowrap;
        }
    </style>
    <!-- Load ONNX runtime first, then VAD -->
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.14.0/dist/ort.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.19/dist/bundle.min.js"></script>
    <script src="https://unpkg.com/wavesurfer.js@7"></script>
</head>
<body>
    <h1>üéõÔ∏è VAD Tuner - Simplified Documentation Pattern</h1>
    <p>Tune VAD settings in real-time using the official documentation pattern</p>
    
    <div class="controls-section">
        <h3>üéõÔ∏è VAD Settings</h3>
        <div class="controls-grid">
            <div class="control-group">
                <label for="positiveSpeechThreshold">Positive Speech Threshold:</label>
                <input type="range" id="positiveSpeechThreshold" min="0.1" max="0.9" step="0.05" value="0.5">
                <span id="positiveSpeechThreshold-value">0.5</span>
            </div>
            
            <div class="control-group">
                <label for="negativeSpeechThreshold">Negative Speech Threshold:</label>
                <input type="range" id="negativeSpeechThreshold" min="0.05" max="0.6" step="0.05" value="0.35">
                <span id="negativeSpeechThreshold-value">0.35</span>
            </div>
            
            <div class="control-group">
                <label for="minSpeechFrames">Min Speech Frames:</label>
                <input type="range" id="minSpeechFrames" min="1" max="20" step="1" value="6">
                <span id="minSpeechFrames-value">6</span>
            </div>
            
            <div class="control-group">
                <label for="redemptionFrames">Redemption Frames:</label>
                <input type="range" id="redemptionFrames" min="8" max="64" step="4" value="24">
                <span id="redemptionFrames-value">24</span>
            </div>
            
            <div class="control-group">
                <label for="padding">Padding (seconds):</label>
                <input type="range" id="padding" min="0.0" max="0.3" step="0.01" value="0.10">
                <span id="padding-value">0.10</span>
            </div>
        </div>
        
        <div class="control-buttons">
            <button onclick="runCustomVAD()" class="primary-btn">üîÑ Test Current Settings</button>
            <button onclick="resetToDefaults()" class="secondary-btn">‚Ü∫ Reset to Defaults</button>
            <button onclick="loadPreset('conservative')" class="preset-btn">üõ°Ô∏è Conservative</button>
            <button onclick="loadPreset('balanced')" class="preset-btn">‚öñÔ∏è Balanced</button>
            <button onclick="loadPreset('aggressive')" class="preset-btn">üéØ Aggressive</button>
        </div>
    </div>
    
    <div class="audio-section">
        <h3>üéµ Audio Visualization & Results</h3>
        <audio id="audio-player" controls style="width: 100%; margin-bottom: 10px;"></audio>
        
        <h4>Waveform:</h4>
        <div id="waveform" style="height: 80px; background: #f0f0f0;"></div>
        
        <h4>Spectrogram with VAD Markers:</h4>
        <div style="font-size: 12px; color: #666; margin-bottom: 5px;">
            üü¢ Green lines = Speech start | üî¥ Red lines = Speech end | üü° Yellow regions = Detected speech
        </div>
        <div id="spectrogram" style="height: 200px; background: #f0f0f0;"></div>
        
        <h4>VAD Timeline:</h4>
        <div id="vad-overlay" style="position: relative; height: 20px; background: rgba(0,0,0,0.1); margin-top: 5px;"></div>
    </div>
    
    <div id="results"></div>

    <script>
        let wavesurfer = null;
        let currentAudioBuffer = null;
        let currentVADSegments = [];
        
        function addResult(text, type = '') {
            const div = document.createElement('div');
            div.className = `result ${type}`;
            div.textContent = text;
            document.getElementById('results').appendChild(div);
            document.getElementById('results').scrollTop = document.getElementById('results').scrollHeight;
        }

        // Get current settings from UI controls
        function getCurrentSettings() {
            return {
                positiveSpeechThreshold: parseFloat(document.getElementById('positiveSpeechThreshold').value),
                negativeSpeechThreshold: parseFloat(document.getElementById('negativeSpeechThreshold').value),
                minSpeechFrames: parseInt(document.getElementById('minSpeechFrames').value),
                redemptionFrames: parseInt(document.getElementById('redemptionFrames').value),
                padding: parseFloat(document.getElementById('padding').value)
            };
        }

        // Update UI display values
        function updateDisplayValues() {
            ['positiveSpeechThreshold', 'negativeSpeechThreshold', 'minSpeechFrames', 'redemptionFrames', 'padding'].forEach(id => {
                const input = document.getElementById(id);
                const display = document.getElementById(id + '-value');
                display.textContent = input.value;
            });
        }

        // Run VAD with custom settings
        async function runCustomVAD() {
            const settings = getCurrentSettings();
            addResult(`\nüéõÔ∏è Testing with custom settings:
${JSON.stringify(settings, null, 2)}`);
            
            await testSimplifiedVADWithSettings(settings);
        }

        // Reset to default settings
        function resetToDefaults() {
            document.getElementById('positiveSpeechThreshold').value = 0.5;
            document.getElementById('negativeSpeechThreshold').value = 0.35;
            document.getElementById('minSpeechFrames').value = 6;
            document.getElementById('redemptionFrames').value = 24;
            document.getElementById('padding').value = 0.10;
            updateDisplayValues();
            addResult('üîÑ Reset to default settings');
        }

        // Load preset configurations
        function loadPreset(presetName) {
            const presets = {
                conservative: {
                    positiveSpeechThreshold: 0.7,
                    negativeSpeechThreshold: 0.5,
                    minSpeechFrames: 10,
                    redemptionFrames: 16,
                    padding: 0.15
                },
                balanced: {
                    positiveSpeechThreshold: 0.5,
                    negativeSpeechThreshold: 0.35,
                    minSpeechFrames: 6,
                    redemptionFrames: 24,
                    padding: 0.10
                },
                aggressive: {
                    positiveSpeechThreshold: 0.3,
                    negativeSpeechThreshold: 0.2,
                    minSpeechFrames: 3,
                    redemptionFrames: 32,
                    padding: 0.05
                }
            };

            const preset = presets[presetName];
            if (preset) {
                document.getElementById('positiveSpeechThreshold').value = preset.positiveSpeechThreshold;
                document.getElementById('negativeSpeechThreshold').value = preset.negativeSpeechThreshold;
                document.getElementById('minSpeechFrames').value = preset.minSpeechFrames;
                document.getElementById('redemptionFrames').value = preset.redemptionFrames;
                document.getElementById('padding').value = preset.padding;
                updateDisplayValues();
                addResult(`üìã Loaded ${presetName} preset`);
            }
        }
        
        async function visualizeAudio() {
            addResult('Loading and visualizing patth.wav...');
            
            try {
                // Load audio
                const response = await fetch('/patth.wav');
                const blob = await response.blob();
                const audioUrl = URL.createObjectURL(blob);
                
                // Set up audio player
                document.getElementById('audio-player').src = audioUrl;
                
                // Decode audio for analysis
                const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const arrayBuffer = await blob.arrayBuffer();
                currentAudioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                
                // Initialize WaveSurfer
                if (wavesurfer) {
                    wavesurfer.destroy();
                }
                
                // Import WaveSurfer plugins
                const { default: WaveSurfer } = await import('https://unpkg.com/wavesurfer.js@7/dist/wavesurfer.esm.js');
                const { default: Spectrogram } = await import('https://unpkg.com/wavesurfer.js@7/dist/plugins/spectrogram.esm.js');
                
                wavesurfer = WaveSurfer.create({
                    container: '#waveform',
                    waveColor: '#4F4A85',
                    progressColor: '#383351',
                    height: 80,
                    normalize: true,
                    barWidth: 2,
                    barRadius: 3
                });
                
                // Add spectrogram
                const spectrogramPlugin = Spectrogram.create({
                    container: '#spectrogram',
                    labels: true,
                    height: 200,
                    splitChannels: false,
                    fftSamples: 512,
                    windowFunc: 'hann'
                });
                
                wavesurfer.registerPlugin(spectrogramPlugin);
                wavesurfer.load(audioUrl);
                
                wavesurfer.on('ready', () => {
                    addResult(`Visualization ready: ${currentAudioBuffer.duration.toFixed(3)}s`, 'success');
                    drawVADOverlay();
                    drawSpectrogramMarkers();
                });
                
            } catch (error) {
                addResult(`Visualization error: ${error.message}`, 'error');
            }
        }
        
        function drawVADOverlay() {
            const overlay = document.getElementById('vad-overlay');
            overlay.innerHTML = '';
            
            if (currentVADSegments.length === 0) {
                overlay.innerHTML = '<div style="text-align: center; line-height: 20px; color: #999;">No VAD segments to display</div>';
                return;
            }
            
            const duration = currentAudioBuffer.duration;
            
            currentVADSegments.forEach((segment, index) => {
                const startPercent = (segment.startTime / duration) * 100;
                const widthPercent = ((segment.endTime - segment.startTime) / duration) * 100;
                
                const segmentDiv = document.createElement('div');
                segmentDiv.style.cssText = `
                    position: absolute;
                    left: ${startPercent}%;
                    width: ${widthPercent}%;
                    height: 100%;
                    background: rgba(255, 0, 0, 0.6);
                    border: 1px solid red;
                    box-sizing: border-box;
                `;
                segmentDiv.title = `Segment ${index + 1}: ${segment.startTime.toFixed(3)}s - ${segment.endTime.toFixed(3)}s`;
                overlay.appendChild(segmentDiv);
            });
        }
        
        function drawSpectrogramMarkers() {
            if (!currentAudioBuffer || currentVADSegments.length === 0) return;
            
            const spectrogramContainer = document.getElementById('spectrogram');
            const duration = currentAudioBuffer.duration;
            
            // Clear existing markers
            spectrogramContainer.querySelectorAll('.vad-marker, .vad-region, .marker-label').forEach(el => el.remove());
            
            currentVADSegments.forEach((segment, index) => {
                const startPercent = (segment.startTime / duration) * 100;
                const endPercent = (segment.endTime / duration) * 100;
                const widthPercent = endPercent - startPercent;
                
                // Create background region
                const region = document.createElement('div');
                region.className = 'vad-region';
                region.style.left = startPercent + '%';
                region.style.width = widthPercent + '%';
                region.title = `VAD Segment ${index + 1}: ${segment.startTime.toFixed(3)}s - ${segment.endTime.toFixed(3)}s`;
                spectrogramContainer.appendChild(region);
                
                // Create start marker
                const startMarker = document.createElement('div');
                startMarker.className = 'vad-marker start';
                startMarker.style.left = startPercent + '%';
                spectrogramContainer.appendChild(startMarker);
                
                // Create start label
                const startLabel = document.createElement('div');
                startLabel.className = 'marker-label';
                startLabel.style.left = startPercent + '%';
                startLabel.textContent = `${segment.startTime.toFixed(3)}s`;
                spectrogramContainer.appendChild(startLabel);
                
                // Create end marker
                const endMarker = document.createElement('div');
                endMarker.className = 'vad-marker end';
                endMarker.style.left = endPercent + '%';
                spectrogramContainer.appendChild(endMarker);
                
                // Create end label
                const endLabel = document.createElement('div');
                endLabel.className = 'marker-label';
                endLabel.style.left = endPercent + '%';
                endLabel.style.top = '-35px'; // Offset to avoid overlap with start label
                endLabel.textContent = `${segment.endTime.toFixed(3)}s`;
                spectrogramContainer.appendChild(endLabel);
            });
            
            addResult(`Added ${currentVADSegments.length} VAD markers to spectrogram`, 'success');
        }

        // Test simplified VAD with custom settings
        async function testSimplifiedVADWithSettings(customSettings = null) {
            const settings = customSettings || {
                positiveSpeechThreshold: 0.5,
                negativeSpeechThreshold: 0.35,
                minSpeechFrames: 6,
                redemptionFrames: 24,
                padding: 0.10
            };
            
            addResult(`=== TESTING SIMPLIFIED VAD WITH ${customSettings ? 'CUSTOM' : 'DEFAULT'} SETTINGS ===`);
            
            try {
                if (!window.vad) {
                    addResult('VAD not available!', 'error');
                    return;
                }
                
                // Load original audio if not already loaded
                if (!currentAudioBuffer) {
                    const response = await fetch('/patth.wav');
                    const blob = await response.blob();
                    const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    const arrayBuffer = await blob.arrayBuffer();
                    currentAudioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                }
                
                addResult(`Audio Properties:
Sample Rate: ${currentAudioBuffer.sampleRate}Hz (native)
Duration: ${currentAudioBuffer.duration.toFixed(3)}s
Expected speech region: 0.5s - 1.2s (from visual analysis)`);
                
                // Create VAD instance with custom settings
                addResult('\n--- Creating VAD with Custom Settings ---');
                const vadConfig = {
                    positiveSpeechThreshold: settings.positiveSpeechThreshold,
                    negativeSpeechThreshold: settings.negativeSpeechThreshold,
                    redemptionFrames: settings.redemptionFrames,
                    frameSamples: 1536,
                    minSpeechFrames: settings.minSpeechFrames,
                    preSpeechPadFrames: 4,
                    positiveSpeechPadFrames: 4
                };
                
                addResult(`VAD Config: ${JSON.stringify(vadConfig, null, 2)}`);
                
                const myvad = await window.vad.NonRealTimeVAD.new(vadConfig);
                addResult('‚úÖ VAD instance created with custom settings');
                
                // Get audio data and native sample rate (exactly as in docs)
                const audioFileData = currentAudioBuffer.getChannelData(0);
                const nativeSampleRate = currentAudioBuffer.sampleRate;
                
                addResult(`\nProcessing ${audioFileData.length} samples at native ${nativeSampleRate}Hz...`);
                
                let segmentCount = 0;
                const segments = [];
                
                // Use the exact pattern from documentation
                for await (const {audio, start, end} of myvad.run(audioFileData, nativeSampleRate)) {
                    segmentCount++;
                    
                    // start and end are in MILLISECONDS according to docs
                    const startSeconds = start / 1000;
                    const endSeconds = end / 1000;
                    const durationMs = end - start;
                    
                    segments.push({ startSeconds, endSeconds, startMs: start, endMs: end });
                    
                    addResult(`Segment ${segmentCount}:`);
                    addResult(`  Raw values: start=${start}ms, end=${end}ms`);
                    addResult(`  Time: ${startSeconds.toFixed(3)}s - ${endSeconds.toFixed(3)}s`);
                    addResult(`  Duration: ${durationMs}ms`);
                    addResult(`  Audio samples: ${audio ? audio.length : 'N/A'}`);
                    
                    // Check if this overlaps with expected speech region (0.5s - 1.2s)
                    if (startSeconds < 1.2 && endSeconds > 0.5) {
                        addResult(`  ‚úÖ OVERLAPS with expected speech region!`);
                    } else {
                        addResult(`  ‚ö†Ô∏è Outside expected speech region (0.5s - 1.2s)`);
                    }
                }
                
                addResult(`\n=== VAD RESULTS ===`);
                if (segmentCount === 0) {
                    addResult(`‚ùå NO SPEECH SEGMENTS DETECTED`, 'error');
                    addResult('Try adjusting sensitivity settings (lower thresholds)', 'warning');
                } else {
                    addResult(`‚úÖ Found ${segmentCount} speech segments`, 'success');
                    
                    // Check if any segment is in the expected region
                    const foundExpectedSpeech = segments.some(seg => 
                        seg.startSeconds < 1.2 && seg.endSeconds > 0.5
                    );
                    
                    if (foundExpectedSpeech) {
                        addResult(`‚úÖ SUCCESS: Found speech in expected region (0.5s - 1.2s)`, 'success');
                        
                        // Update visualization if available
                        currentVADSegments = segments.map(seg => ({
                            startTime: seg.startSeconds,
                            endTime: seg.endSeconds
                        }));
                        
                        if (wavesurfer && currentAudioBuffer) {
                            drawSpectrogramMarkers();
                            drawVADOverlay();
                        }
                        
                        // Create trimmed audio preview with custom padding
                        await createTrimmedAudioPreview(segments, settings.padding);
                        
                    } else {
                        addResult(`‚ö†Ô∏è WARNING: No segments in expected speech region`, 'warning');
                        addResult('Try more aggressive settings (lower thresholds)', 'warning');
                    }
                    
                    // Show timing comparison
                    addResult('\nTiming Analysis:');
                    const earliestStart = Math.min(...segments.map(s => s.startSeconds));
                    const latestEnd = Math.max(...segments.map(s => s.endSeconds));
                    addResult(`Overall speech span: ${earliestStart.toFixed(3)}s - ${latestEnd.toFixed(3)}s`);
                    addResult(`Expected span: 0.500s - 1.200s`);
                    addResult(`Timing accuracy: ${Math.abs(earliestStart - 0.5) < 0.1 && Math.abs(latestEnd - 1.2) < 0.3 ? 'GOOD' : 'NEEDS REVIEW'}`);
                }
                
            } catch (error) {
                addResult(`Simplified VAD error: ${error.message}`, 'error');
                console.error('Simplified VAD error details:', error);
            }
        }

        // Wrapper for default settings (for auto-run)
        async function testSimplifiedVAD() {
            await testSimplifiedVADWithSettings();
        }

        // Add audio trimming preview functionality
        async function createTrimmedAudioPreview(segments, customPadding = 0.1) {
            if (!currentAudioBuffer || segments.length === 0) return;
            
            try {
                addResult('\n--- Creating Trimmed Audio Preview ---');
                
                // Calculate overall boundaries with padding
                const earliestStart = Math.min(...segments.map(s => s.startSeconds));
                const latestEnd = Math.max(...segments.map(s => s.endSeconds));
                const padding = customPadding; // Use custom padding from settings
                
                const trimStart = Math.max(0, earliestStart - padding);
                const trimEnd = Math.min(currentAudioBuffer.duration, latestEnd + padding);
                
                addResult(`Original duration: ${currentAudioBuffer.duration.toFixed(3)}s`);
                addResult(`Speech detected: ${earliestStart.toFixed(3)}s - ${latestEnd.toFixed(3)}s`);
                addResult(`With padding: ${trimStart.toFixed(3)}s - ${trimEnd.toFixed(3)}s`);
                addResult(`Trimmed duration: ${(trimEnd - trimStart).toFixed(3)}s`);
                
                // Create trimmed audio buffer
                const sampleRate = currentAudioBuffer.sampleRate;
                const startSample = Math.floor(trimStart * sampleRate);
                const endSample = Math.floor(trimEnd * sampleRate);
                const trimmedLength = endSample - startSample;
                
                const trimmedBuffer = new AudioContext().createBuffer(
                    currentAudioBuffer.numberOfChannels,
                    trimmedLength,
                    sampleRate
                );
                
                // Copy trimmed audio data
                for (let channel = 0; channel < currentAudioBuffer.numberOfChannels; channel++) {
                    const originalData = currentAudioBuffer.getChannelData(channel);
                    const trimmedData = trimmedBuffer.getChannelData(channel);
                    
                    for (let i = 0; i < trimmedLength; i++) {
                        const sourceIndex = startSample + i;
                        trimmedData[i] = sourceIndex < originalData.length ? originalData[sourceIndex] : 0;
                    }
                }
                
                // Convert to blob and create preview
                const trimmedBlob = await audioBufferToBlob(trimmedBuffer);
                const trimmedUrl = URL.createObjectURL(trimmedBlob);
                
                // Create audio preview element
                const previewContainer = document.createElement('div');
                previewContainer.innerHTML = `
                    <h4>üéµ Trimmed Audio Preview</h4>
                    <p>This is what the audio would sound like after VAD trimming:</p>
                    <audio controls style="width: 100%; margin: 10px 0;">
                        <source src="${trimmedUrl}" type="audio/wav">
                    </audio>
                    <p><strong>Reduction:</strong> ${((currentAudioBuffer.duration - (trimEnd - trimStart)) / currentAudioBuffer.duration * 100).toFixed(1)}% shorter</p>
                `;
                
                // Add to audio section
                const audioSection = document.querySelector('.audio-section');
                
                // Remove existing preview if any
                const existingPreview = audioSection.querySelector('.trimmed-preview');
                if (existingPreview) {
                    existingPreview.remove();
                }
                
                previewContainer.className = 'trimmed-preview';
                previewContainer.style.cssText = `
                    margin: 20px 0;
                    padding: 15px;
                    background: #e8f5e8;
                    border: 2px solid #28a745;
                    border-radius: 8px;
                `;
                audioSection.appendChild(previewContainer);
                
                addResult('‚úÖ Trimmed audio preview created!', 'success');
                
            } catch (error) {
                addResult(`Error creating audio preview: ${error.message}`, 'error');
            }
        }

        // Convert AudioBuffer to WAV Blob
        async function audioBufferToBlob(audioBuffer) {
            const numberOfChannels = audioBuffer.numberOfChannels;
            const sampleRate = audioBuffer.sampleRate;
            const length = audioBuffer.length;
            const bytesPerSample = 2; // 16-bit PCM
            const blockAlign = numberOfChannels * bytesPerSample;
            const byteRate = sampleRate * blockAlign;
            const dataSize = length * blockAlign;
            const bufferSize = 44 + dataSize;
            
            const arrayBuffer = new ArrayBuffer(bufferSize);
            const view = new DataView(arrayBuffer);
            
            // Write WAV header
            const writeString = (offset, string) => {
                for (let i = 0; i < string.length; i++) {
                    view.setUint8(offset + i, string.charCodeAt(i));
                }
            };
            
            writeString(0, 'RIFF');
            view.setUint32(4, bufferSize - 8, true);
            writeString(8, 'WAVE');
            writeString(12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true);
            view.setUint16(22, numberOfChannels, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, byteRate, true);
            view.setUint16(32, blockAlign, true);
            view.setUint16(34, 16, true);
            writeString(36, 'data');
            view.setUint32(40, dataSize, true);
            
            // Convert and write audio samples
            let offset = 44;
            for (let i = 0; i < length; i++) {
                for (let channel = 0; channel < numberOfChannels; channel++) {
                    const sample = Math.max(-1, Math.min(1, audioBuffer.getChannelData(channel)[i]));
                    view.setInt16(offset, sample * 0x7FFF, true);
                    offset += 2;
                }
            }
            
            return new Blob([arrayBuffer], { type: 'audio/wav' });
        }

        // Make essential functions available globally
        window.visualizeAudio = visualizeAudio;
        window.testSimplifiedVAD = testSimplifiedVAD;
        window.runCustomVAD = runCustomVAD;
        window.resetToDefaults = resetToDefaults;
        window.loadPreset = loadPreset;

        // Initialize sliders and auto-run
        document.addEventListener('DOMContentLoaded', async () => {
            addResult('üéõÔ∏è VAD Tuner Ready', 'success');
            addResult('Auto-loading audio and running simplified VAD documentation pattern...', 'info');
            
            // Set up slider event listeners
            ['positiveSpeechThreshold', 'negativeSpeechThreshold', 'minSpeechFrames', 'redemptionFrames', 'padding'].forEach(id => {
                const input = document.getElementById(id);
                input.addEventListener('input', updateDisplayValues);
            });
            
            // Initialize display values
            updateDisplayValues();
            
            // Wait for libraries to load, then auto-run
            setTimeout(async () => {
                try {
                    // Load visualization first
                    await visualizeAudio();
                    
                    // Wait for waveform to be ready, then run simplified VAD
                    setTimeout(async () => {
                        await testSimplifiedVAD();
                    }, 2000);
                } catch (error) {
                    addResult(`Auto-run error: ${error.message}`, 'error');
                }
            }, 1000);
        });
    </script>
</body>
</html>