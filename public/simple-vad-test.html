<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>VAD Tuner - Simplified Documentation Pattern</title>
    <style>
        body { font-family: Arial, sans-serif; padding: 20px; max-width: 1200px; margin: 0 auto; }
        .result { background: #f0f0f0; padding: 10px; margin: 10px 0; font-family: monospace; white-space: pre-wrap; }
        .success { background: #d4edda; }
        .error { background: #f8d7da; }
        .warning { background: #fff3cd; }
        
        .controls-section {
            margin: 20px 0;
            padding: 20px;
            border: 2px solid #007bff;
            border-radius: 12px;
            background: #f8f9fa;
        }
        .controls-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 15px;
            margin: 15px 0;
        }
        .control-group {
            display: flex;
            flex-direction: column;
            gap: 5px;
        }
        .control-group label {
            font-weight: bold;
            color: #495057;
            font-size: 14px;
        }
        .control-group input[type="range"] {
            width: 100%;
            margin: 5px 0;
        }
        .control-group span {
            font-family: monospace;
            font-weight: bold;
            color: #007bff;
            text-align: center;
            background: white;
            padding: 2px 8px;
            border-radius: 4px;
            border: 1px solid #dee2e6;
        }
        .control-buttons {
            display: flex;
            gap: 10px;
            margin-top: 20px;
            flex-wrap: wrap;
        }
        .primary-btn {
            background: #28a745;
            color: white;
            border: none;
            padding: 12px 24px;
            border-radius: 6px;
            font-weight: bold;
            cursor: pointer;
            font-size: 16px;
        }
        .primary-btn:hover { background: #218838; }
        .secondary-btn {
            background: #6c757d;
            color: white;
            border: none;
            padding: 12px 24px;
            border-radius: 6px;
            font-weight: bold;
            cursor: pointer;
        }
        .secondary-btn:hover { background: #545b62; }
        .preset-btn {
            background: #17a2b8;
            color: white;
            border: none;
            padding: 10px 16px;
            border-radius: 6px;
            cursor: pointer;
            font-size: 14px;
        }
        .preset-btn:hover { background: #138496; }
        
        .audio-section {
            margin: 20px 0;
            padding: 15px;
            border: 1px solid #ddd;
            border-radius: 8px;
            background: #f9f9f9;
        }
        #waveform, #spectrogram {
            margin: 10px 0;
            border: 1px solid #ccc;
            border-radius: 4px;
            position: relative;
        }
        .vad-marker {
            position: absolute;
            top: 0;
            bottom: 0;
            border-left: 2px solid #ff0000;
            pointer-events: none;
            z-index: 10;
        }
        .vad-marker.start {
            border-left: 3px solid #00ff00;
        }
        .vad-marker.end {
            border-left: 3px solid #ff0000;
        }
        .vad-region {
            position: absolute;
            top: 0;
            bottom: 0;
            background: rgba(255, 255, 0, 0.2);
            pointer-events: none;
            z-index: 5;
            border: 1px solid rgba(255, 255, 0, 0.6);
        }
        .marker-label {
            position: absolute;
            top: -20px;
            font-size: 10px;
            color: #333;
            background: rgba(255, 255, 255, 0.8);
            padding: 1px 3px;
            border-radius: 2px;
            white-space: nowrap;
        }
    </style>
    <!-- Load ONNX runtime first, then VAD -->
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.14.0/dist/ort.min.js"></script>
    <script>
        // Suppress ONNX runtime warnings by setting log level to error only
        if (typeof ort !== 'undefined') {
            ort.env.logLevel = 'error';
        }
    </script>
    <script src="https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.19/dist/bundle.min.js"></script>
    <script src="https://unpkg.com/wavesurfer.js@7"></script>
</head>
<body>
    <h1>üéõÔ∏è VAD Tuner - Simplified Documentation Pattern</h1>
    <p>Tune VAD settings in real-time using the official documentation pattern</p>
    
    <div class="controls-section">
        <h3>üéõÔ∏è VAD Settings</h3>
        <div class="controls-grid">
            <div class="control-group">
                <label for="positiveSpeechThreshold">Positive Speech Threshold:</label>
                <input type="range" id="positiveSpeechThreshold" min="0.1" max="0.9" step="0.05" value="0.3">
                <span id="positiveSpeechThreshold-value">0.5</span>
            </div>
            
            <div class="control-group">
                <label for="negativeSpeechThreshold">Negative Speech Threshold:</label>
                <input type="range" id="negativeSpeechThreshold" min="0.05" max="0.6" step="0.05" value="0.2">
                <span id="negativeSpeechThreshold-value">0.2</span>
            </div>
            
            <div class="control-group">
                <label for="minSpeechFrames">Min Speech Frames:</label>
                <input type="range" id="minSpeechFrames" min="1" max="20" step="1" value="3">
                <span id="minSpeechFrames-value">3</span>
            </div>
            
            <div class="control-group">
                <label for="redemptionFrames">Redemption Frames:</label>
                <input type="range" id="redemptionFrames" min="8" max="64" step="4" value="32">
                <span id="redemptionFrames-value">32</span>
            </div>
            
            <div class="control-group">
                <label for="padding">Padding (seconds):</label>
                <input type="range" id="padding" min="0.0" max="0.3" step="0.01" value="0.05">
                <span id="padding-value">0.05</span>
            </div>
        </div>
        
        <div class="control-buttons">
            <button onclick="runCustomVAD()" class="primary-btn">üîÑ Test Current Settings</button>
            <button onclick="resetToDefaults()" class="secondary-btn">‚Ü∫ Reset to Defaults</button>
            <button onclick="loadPreset('conservative')" class="preset-btn">üõ°Ô∏è Conservative</button>
            <button onclick="loadPreset('balanced')" class="preset-btn">‚öñÔ∏è Balanced</button>
            <button onclick="loadPreset('aggressive')" class="preset-btn">üéØ Aggressive</button>
        </div>
    </div>
    
    <div class="audio-section">
        <h3>üéµ Audio Visualization & Results</h3>
        <audio id="audio-player" controls style="width: 100%; margin-bottom: 10px;"></audio>
        
        <h4>Waveform:</h4>
        <div id="waveform" style="height: 80px; background: #f0f0f0;"></div>
        
        <h4>Original Spectrogram with VAD Markers:</h4>
        <div style="font-size: 12px; color: #666; margin-bottom: 5px;">
            üü¢ Green lines = Speech start | üî¥ Red lines = Speech end | üü° Yellow regions = Detected speech
        </div>
        <div id="spectrogram" style="height: 200px; background: #f0f0f0;"></div>
        
        <h4>Trimmed Audio Preview Spectrogram:</h4>
        <div style="font-size: 12px; color: #666; margin-bottom: 5px;">
            Shows what the audio will look like after VAD trimming and padding
        </div>
        <div id="trimmed-spectrogram" style="height: 150px; background: #f0f0f0; display: none;"></div>
        
        <h4>VAD Timeline:</h4>
        <div id="vad-overlay" style="position: relative; height: 20px; background: rgba(0,0,0,0.1); margin-top: 5px;"></div>
    </div>
    
    <div id="results"></div>

    <script>
        let wavesurfer = null;
        let currentAudioBuffer = null;
        let currentVADSegments = [];
        let spectrogramErrorCount = 0;
        let disableVisualizationUpdates = false;
        let trimmedWavesurfer = null; // Track trimmed audio wavesurfer instance
        let currentTrimmedUrl = null; // Track current trimmed audio blob URL for cleanup
        
        function addResult(text, type = '') {
            const div = document.createElement('div');
            div.className = `result ${type}`;
            div.textContent = text;
            document.getElementById('results').appendChild(div);
            document.getElementById('results').scrollTop = document.getElementById('results').scrollHeight;
        }

        // Get current settings from UI controls
        function getCurrentSettings() {
            return {
                positiveSpeechThreshold: parseFloat(document.getElementById('positiveSpeechThreshold').value),
                negativeSpeechThreshold: parseFloat(document.getElementById('negativeSpeechThreshold').value),
                minSpeechFrames: parseInt(document.getElementById('minSpeechFrames').value),
                redemptionFrames: parseInt(document.getElementById('redemptionFrames').value),
                padding: parseFloat(document.getElementById('padding').value)
            };
        }

        // Update UI display values
        function updateDisplayValues() {
            ['positiveSpeechThreshold', 'negativeSpeechThreshold', 'minSpeechFrames', 'redemptionFrames', 'padding'].forEach(id => {
                const input = document.getElementById(id);
                const display = document.getElementById(id + '-value');
                display.textContent = input.value;
            });
        }

        // Run VAD with custom settings
        async function runCustomVAD() {
            const settings = getCurrentSettings();
            addResult(`\nüéõÔ∏è Testing with custom settings:
${JSON.stringify(settings, null, 2)}`);
            
            // Run VAD analysis only, don't recreate visualization
            await runVADAnalysisOnly(settings);
        }

        // Reset to default settings (aggressive)
        function resetToDefaults() {
            document.getElementById('positiveSpeechThreshold').value = 0.3;
            document.getElementById('negativeSpeechThreshold').value = 0.2;
            document.getElementById('minSpeechFrames').value = 3;
            document.getElementById('redemptionFrames').value = 32;
            document.getElementById('padding').value = 0.05;
            updateDisplayValues();
            addResult('üîÑ Reset to default settings (aggressive)');
        }

        // Load preset configurations
        function loadPreset(presetName) {
            const presets = {
                conservative: {
                    positiveSpeechThreshold: 0.7,
                    negativeSpeechThreshold: 0.5,
                    minSpeechFrames: 10,
                    redemptionFrames: 16,
                    padding: 0.15
                },
                balanced: {
                    positiveSpeechThreshold: 0.5,
                    negativeSpeechThreshold: 0.35,
                    minSpeechFrames: 6,
                    redemptionFrames: 24,
                    padding: 0.10
                },
                aggressive: {
                    positiveSpeechThreshold: 0.3,
                    negativeSpeechThreshold: 0.2,
                    minSpeechFrames: 3,
                    redemptionFrames: 32,
                    padding: 0.05
                }
            };

            const preset = presets[presetName];
            if (preset) {
                document.getElementById('positiveSpeechThreshold').value = preset.positiveSpeechThreshold;
                document.getElementById('negativeSpeechThreshold').value = preset.negativeSpeechThreshold;
                document.getElementById('minSpeechFrames').value = preset.minSpeechFrames;
                document.getElementById('redemptionFrames').value = preset.redemptionFrames;
                document.getElementById('padding').value = preset.padding;
                updateDisplayValues();
                addResult(`üìã Loaded ${presetName} preset`);
            }
        }
        
        async function visualizeAudio() {
            addResult('Loading and visualizing test_said_three_words.mp3...');
            
            try {
                // Load audio
                const response = await fetch('/test_said_three_words.mp3');
                const blob = await response.blob();
                const audioUrl = URL.createObjectURL(blob);
                
                // Set up audio player
                document.getElementById('audio-player').src = audioUrl;
                
                // Decode audio for analysis
                const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const arrayBuffer = await blob.arrayBuffer();
                currentAudioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                
                // Initialize WaveSurfer
                if (wavesurfer) {
                    wavesurfer.destroy();
                }
                
                // Import WaveSurfer plugins
                const { default: WaveSurfer } = await import('https://unpkg.com/wavesurfer.js@7/dist/wavesurfer.esm.js');
                const { default: Spectrogram } = await import('https://unpkg.com/wavesurfer.js@7/dist/plugins/spectrogram.esm.js');
                
                wavesurfer = WaveSurfer.create({
                    container: '#waveform',
                    waveColor: '#4F4A85',
                    progressColor: '#383351',
                    height: 80,
                    normalize: true,
                    barWidth: 2,
                    barRadius: 3
                });
                
                // Add spectrogram with proper error handling
                try {
                    const spectrogramPlugin = Spectrogram.create({
                        container: '#spectrogram',
                        labels: true,
                        height: 200,
                        splitChannels: false,
                        fftSamples: 512,
                        windowFunc: 'hann'
                    });
                    
                    wavesurfer.registerPlugin(spectrogramPlugin);
                } catch (spectrogramError) {
                    console.warn('Spectrogram plugin failed, continuing without spectrogram:', spectrogramError);
                    addResult('Note: Spectrogram visualization unavailable, but VAD processing will continue', 'warning');
                }
                wavesurfer.load(audioUrl);
                
                wavesurfer.on('ready', () => {
                    addResult(`Visualization ready: ${currentAudioBuffer.duration.toFixed(3)}s`, 'success');
                    drawVADOverlay();
                    drawSpectrogramMarkers();
                });
                
                // Add error handling for spectrogram
                wavesurfer.on('error', (error) => {
                    console.warn('WaveSurfer error (non-critical):', error);
                    // Continue execution - spectrogram errors are not critical
                });
                
            } catch (error) {
                addResult(`Visualization error: ${error.message}`, 'error');
            }
        }
        
        function drawVADOverlay() {
            const overlay = document.getElementById('vad-overlay');
            overlay.innerHTML = '';
            
            if (!currentAudioBuffer || currentVADSegments.length === 0) {
                overlay.innerHTML = '<div style="text-align: center; line-height: 20px; color: #999;">No VAD segments detected with current settings</div>';
                return;
            }
            
            const duration = currentAudioBuffer.duration;
            
            currentVADSegments.forEach((segment, index) => {
                const startPercent = (segment.startTime / duration) * 100;
                const widthPercent = ((segment.endTime - segment.startTime) / duration) * 100;
                
                const segmentDiv = document.createElement('div');
                segmentDiv.style.cssText = `
                    position: absolute;
                    left: ${startPercent}%;
                    width: ${widthPercent}%;
                    height: 100%;
                    background: rgba(255, 0, 0, 0.6);
                    border: 1px solid red;
                    box-sizing: border-box;
                `;
                segmentDiv.title = `Segment ${index + 1}: ${segment.startTime.toFixed(3)}s - ${segment.endTime.toFixed(3)}s`;
                overlay.appendChild(segmentDiv);
            });
        }
        
        function drawSpectrogramMarkers() {
            if (disableVisualizationUpdates) {
                addResult('Visualization updates disabled due to persistent errors', 'warning');
                return;
            }
            
            let spectrogramContainer;
            let duration;
            
            try {
                spectrogramContainer = document.getElementById('spectrogram');
                duration = currentAudioBuffer ? currentAudioBuffer.duration : 1;
                
                // Always clear existing markers first
                spectrogramContainer.querySelectorAll('.vad-marker, .vad-region, .marker-label').forEach(el => el.remove());
                
                // If no segments, just return after clearing
                if (!currentAudioBuffer || currentVADSegments.length === 0) {
                    addResult('üßπ Cleared previous VAD markers (no segments detected)', 'warning');
                    return;
                }
            } catch (error) {
                spectrogramErrorCount++;
                console.warn('Error clearing spectrogram markers (non-critical):', error);
                addResult('Note: Visualization update skipped due to spectrogram error', 'warning');
                
                if (spectrogramErrorCount >= 3) {
                    disableVisualizationUpdates = true;
                    addResult('Disabling visualization updates due to persistent errors - VAD analysis will continue', 'error');
                }
                return;
            }
            
            try {
                currentVADSegments.forEach((segment, index) => {
                    const startPercent = (segment.startTime / duration) * 100;
                    const endPercent = (segment.endTime / duration) * 100;
                    const widthPercent = endPercent - startPercent;
                    
                    // Create background region
                    const region = document.createElement('div');
                    region.className = 'vad-region';
                    region.style.left = startPercent + '%';
                    region.style.width = widthPercent + '%';
                    region.title = `VAD Segment ${index + 1}: ${segment.startTime.toFixed(3)}s - ${segment.endTime.toFixed(3)}s`;
                    spectrogramContainer.appendChild(region);
                    
                    // Create start marker
                    const startMarker = document.createElement('div');
                    startMarker.className = 'vad-marker start';
                    startMarker.style.left = startPercent + '%';
                    spectrogramContainer.appendChild(startMarker);
                    
                    // Create start label
                    const startLabel = document.createElement('div');
                    startLabel.className = 'marker-label';
                    startLabel.style.left = startPercent + '%';
                    startLabel.textContent = `${segment.startTime.toFixed(3)}s`;
                    spectrogramContainer.appendChild(startLabel);
                    
                    // Create end marker
                    const endMarker = document.createElement('div');
                    endMarker.className = 'vad-marker end';
                    endMarker.style.left = endPercent + '%';
                    spectrogramContainer.appendChild(endMarker);
                    
                    // Create end label
                    const endLabel = document.createElement('div');
                    endLabel.className = 'marker-label';
                    endLabel.style.left = endPercent + '%';
                    endLabel.style.top = '-35px'; // Offset to avoid overlap with start label
                    endLabel.textContent = `${segment.endTime.toFixed(3)}s`;
                    spectrogramContainer.appendChild(endLabel);
                });
                
                addResult(`Added ${currentVADSegments.length} VAD markers to spectrogram`, 'success');
            } catch (error) {
                console.warn('Error drawing VAD markers (non-critical):', error);
                addResult('Note: VAD markers could not be updated due to visualization error', 'warning');
            }
        }

        // Test simplified VAD with custom settings
        async function testSimplifiedVADWithSettings(customSettings = null) {
            const settings = customSettings || {
                positiveSpeechThreshold: 0.5,  // Aggressive default
                negativeSpeechThreshold: 0.2,  // Aggressive default
                minSpeechFrames: 4,            // Aggressive default
                redemptionFrames: 32,          // Aggressive default
                padding: 0.05                  // Aggressive default
            };
            
            addResult(`=== TESTING SIMPLIFIED VAD WITH ${customSettings ? 'CUSTOM' : 'DEFAULT'} SETTINGS ===`);
            
            try {
                if (!window.vad) {
                    addResult('VAD not available!', 'error');
                    return;
                }
                
                // Load original audio if not already loaded
                if (!currentAudioBuffer) {
                    const response = await fetch('/patth.wav');
                    const blob = await response.blob();
                    const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    const arrayBuffer = await blob.arrayBuffer();
                    currentAudioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                }
                
                addResult(`Audio Properties:
Sample Rate: ${currentAudioBuffer.sampleRate}Hz (native)
Duration: ${currentAudioBuffer.duration.toFixed(3)}s`);
                
                // Create VAD instance with custom settings
                addResult('\n--- Creating VAD with Custom Settings ---');
                const vadConfig = {
                    positiveSpeechThreshold: settings.positiveSpeechThreshold,
                    negativeSpeechThreshold: settings.negativeSpeechThreshold,
                    redemptionFrames: settings.redemptionFrames,
                    frameSamples: 1536,
                    minSpeechFrames: settings.minSpeechFrames,
                    preSpeechPadFrames: 4,
                    positiveSpeechPadFrames: 4
                };
                
                addResult(`VAD Config: ${JSON.stringify(vadConfig, null, 2)}`);
                
                const myvad = await window.vad.NonRealTimeVAD.new(vadConfig);
                addResult('‚úÖ VAD instance created with custom settings');
                
                // Get audio data and native sample rate (exactly as in docs)
                const audioFileData = currentAudioBuffer.getChannelData(0);
                const nativeSampleRate = currentAudioBuffer.sampleRate;
                
                addResult(`\nProcessing ${audioFileData.length} samples at native ${nativeSampleRate}Hz...`);
                
                let segmentCount = 0;
                const segments = [];
                
                // Use the exact pattern from documentation
                for await (const {audio, start, end} of myvad.run(audioFileData, nativeSampleRate)) {
                    segmentCount++;
                    
                    // start and end are in MILLISECONDS according to docs
                    const startSeconds = start / 1000;
                    const endSeconds = end / 1000;
                    const durationMs = end - start;
                    
                    segments.push({ startSeconds, endSeconds, startMs: start, endMs: end });
                    
                    addResult(`Segment ${segmentCount}:`);
                    addResult(`  Raw values: start=${start}ms, end=${end}ms`);
                    addResult(`  Time: ${startSeconds.toFixed(3)}s - ${endSeconds.toFixed(3)}s`);
                    addResult(`  Duration: ${durationMs}ms`);
                    addResult(`  Audio samples: ${audio ? audio.length : 'N/A'}`);
                    addResult(`  ‚úÖ VAD detected speech segment`);
                }
                
                addResult(`\n=== VAD RESULTS ===`);
                if (segmentCount === 0) {
                    addResult(`‚ùå NO SPEECH SEGMENTS DETECTED`, 'error');
                    addResult('Try adjusting sensitivity settings (lower thresholds)', 'warning');
                } else {
                    addResult(`‚úÖ Found ${segmentCount} speech segments`, 'success');
                    
                    // Update visualization if available
                    currentVADSegments = segments.map(seg => ({
                        startTime: seg.startSeconds,
                        endTime: seg.endSeconds
                    }));
                    
                    if (wavesurfer && currentAudioBuffer) {
                        drawSpectrogramMarkers();
                        drawVADOverlay();
                    }
                    
                    // Create trimmed audio preview with custom padding
                    await createTrimmedAudioPreview(segments, settings.padding);
                    
                    // Show timing analysis
                    addResult('\nTiming Analysis:');
                    const earliestStart = Math.min(...segments.map(s => s.startSeconds));
                    const latestEnd = Math.max(...segments.map(s => s.endSeconds));
                    const totalSpeechDuration = segments.reduce((sum, seg) => sum + (seg.endSeconds - seg.startSeconds), 0);
                    const speechCoverage = (totalSpeechDuration / currentAudioBuffer.duration * 100);
                    
                    addResult(`Detected speech span: ${earliestStart.toFixed(3)}s - ${latestEnd.toFixed(3)}s`);
                    addResult(`Total speech duration: ${totalSpeechDuration.toFixed(3)}s`);
                    addResult(`Speech coverage: ${speechCoverage.toFixed(1)}% of total audio`);
                }
                
            } catch (error) {
                addResult(`Simplified VAD error: ${error.message}`, 'error');
                console.error('Simplified VAD error details:', error);
            }
        }

        // Wrapper for default settings (for auto-run)
        async function testSimplifiedVAD() {
            await testSimplifiedVADWithSettings();
        }

        // Run VAD analysis only without recreating visualization
        async function runVADAnalysisOnly(customSettings) {
            const settings = customSettings || {
                positiveSpeechThreshold: 0.3,  // Aggressive default
                negativeSpeechThreshold: 0.2,  // Aggressive default
                minSpeechFrames: 3,            // Aggressive default
                redemptionFrames: 32,          // Aggressive default
                padding: 0.05                  // Aggressive default
            };
            
            addResult(`=== RUNNING VAD ANALYSIS WITH CUSTOM SETTINGS ===`);
            
            try {
                if (!window.vad) {
                    addResult('VAD not available!', 'error');
                    return;
                }
                
                // Use existing audio buffer if available
                if (!currentAudioBuffer) {
                    addResult('No audio loaded. Please run initial test first.', 'error');
                    return;
                }
                
                addResult(`Using existing audio: ${currentAudioBuffer.duration.toFixed(3)}s at ${currentAudioBuffer.sampleRate}Hz`);
                
                // Create VAD instance with custom settings
                addResult('--- Creating VAD with Custom Settings ---');
                const vadConfig = {
                    positiveSpeechThreshold: settings.positiveSpeechThreshold,
                    negativeSpeechThreshold: settings.negativeSpeechThreshold,
                    redemptionFrames: settings.redemptionFrames,
                    frameSamples: 1536,
                    minSpeechFrames: settings.minSpeechFrames,
                    preSpeechPadFrames: 4,
                    positiveSpeechPadFrames: 4
                };
                
                addResult(`VAD Config: ${JSON.stringify(vadConfig, null, 2)}`);
                
                const myvad = await window.vad.NonRealTimeVAD.new(vadConfig);
                addResult('‚úÖ VAD instance created with custom settings');
                
                // Get audio data and native sample rate
                const audioFileData = currentAudioBuffer.getChannelData(0);
                const nativeSampleRate = currentAudioBuffer.sampleRate;
                
                addResult(`Processing ${audioFileData.length} samples at native ${nativeSampleRate}Hz...`);
                
                let segmentCount = 0;
                const segments = [];
                
                // Use the exact pattern from documentation
                for await (const {audio, start, end} of myvad.run(audioFileData, nativeSampleRate)) {
                    segmentCount++;
                    
                    // start and end are in MILLISECONDS according to docs
                    const startSeconds = start / 1000;
                    const endSeconds = end / 1000;
                    const durationMs = end - start;
                    
                    segments.push({ startSeconds, endSeconds, startMs: start, endMs: end });
                    
                    addResult(`Segment ${segmentCount}:`);
                    addResult(`  Raw values: start=${start}ms, end=${end}ms`);
                    addResult(`  Time: ${startSeconds.toFixed(3)}s - ${endSeconds.toFixed(3)}s`);
                    addResult(`  Duration: ${durationMs}ms`);
                    addResult(`  Audio samples: ${audio ? audio.length : 'N/A'}`);
                    addResult(`  ‚úÖ VAD detected speech segment`);
                }
                
                addResult(`\n=== VAD ANALYSIS RESULTS ===`);
                if (segmentCount === 0) {
                    addResult(`‚ùå NO SPEECH SEGMENTS DETECTED`, 'error');
                    addResult('Try adjusting sensitivity settings (lower thresholds)', 'warning');
                    
                    // Clear segments and update visualization
                    currentVADSegments = [];
                    if (wavesurfer && currentAudioBuffer) {
                        drawSpectrogramMarkers();
                        drawVADOverlay();
                    }
                } else {
                    addResult(`‚úÖ Found ${segmentCount} speech segments`, 'success');
                    
                    // Update visualization markers if available
                    currentVADSegments = segments.map(seg => ({
                        startTime: seg.startSeconds,
                        endTime: seg.endSeconds
                    }));
                    
                    if (wavesurfer && currentAudioBuffer) {
                        drawSpectrogramMarkers();
                        drawVADOverlay();
                    }
                    
                    // Create trimmed audio preview with custom padding
                    await createTrimmedAudioPreview(segments, settings.padding);
                    
                    // Show timing analysis
                    addResult('\nTiming Analysis:');
                    const earliestStart = Math.min(...segments.map(s => s.startSeconds));
                    const latestEnd = Math.max(...segments.map(s => s.endSeconds));
                    const totalSpeechDuration = segments.reduce((sum, seg) => sum + (seg.endSeconds - seg.startSeconds), 0);
                    const speechCoverage = (totalSpeechDuration / currentAudioBuffer.duration * 100);
                    
                    addResult(`Detected speech span: ${earliestStart.toFixed(3)}s - ${latestEnd.toFixed(3)}s`);
                    addResult(`Total speech duration: ${totalSpeechDuration.toFixed(3)}s`);
                    addResult(`Speech coverage: ${speechCoverage.toFixed(1)}% of total audio`);
                }
                
            } catch (error) {
                addResult(`VAD analysis error: ${error.message}`, 'error');
                console.error('VAD analysis error details:', error);
            }
        }

        // Add audio trimming preview functionality
        async function createTrimmedAudioPreview(segments, customPadding = 0.1) {
            if (!currentAudioBuffer || segments.length === 0) return;
            
            try {
                addResult('\n--- Creating Trimmed Audio Preview ---');
                
                // Calculate overall boundaries with padding
                const earliestStart = Math.min(...segments.map(s => s.startSeconds));
                const latestEnd = Math.max(...segments.map(s => s.endSeconds));
                
                // Apply padding to both start and end
                const padding = customPadding;
                let trimStart = Math.max(0, earliestStart - padding);
                let trimEnd = Math.min(currentAudioBuffer.duration, latestEnd + padding);
                
                // Diagnostic: Check if we're losing speech at the beginning
                addResult(`Original duration: ${currentAudioBuffer.duration.toFixed(3)}s`);
                addResult(`VAD detected speech: ${earliestStart.toFixed(3)}s - ${latestEnd.toFixed(3)}s`);
                addResult(`Padding applied: ${padding.toFixed(3)}s to both start and end`);
                addResult(`Before trimming: ${trimStart.toFixed(3)}s - ${trimEnd.toFixed(3)}s`);
                
                // Show VAD detection timing
                addResult(`VAD detection timing: Speech starts at ${earliestStart.toFixed(3)}s`);
                
                addResult(`Final trimmed range: ${trimStart.toFixed(3)}s - ${trimEnd.toFixed(3)}s`);
                addResult(`Trimmed duration: ${(trimEnd - trimStart).toFixed(3)}s`);
                
                // Create trimmed audio buffer
                const sampleRate = currentAudioBuffer.sampleRate;
                const startSample = Math.floor(trimStart * sampleRate);
                const endSample = Math.floor(trimEnd * sampleRate);
                const trimmedLength = endSample - startSample;
                
                addResult(`Audio buffer creation debug:`);
                addResult(`  Sample rate: ${sampleRate}Hz`);
                addResult(`  Start sample: ${startSample} (${(startSample / sampleRate).toFixed(3)}s)`);
                addResult(`  End sample: ${endSample} (${(endSample / sampleRate).toFixed(3)}s)`);
                addResult(`  Trimmed length: ${trimmedLength} samples (${(trimmedLength / sampleRate).toFixed(3)}s)`);
                addResult(`  Expected padding at start: ${(trimStart > 0 ? 'YES' : 'NO')} - ${((earliestStart - trimStart) * 1000).toFixed(0)}ms`);
                
                const trimmedBuffer = new AudioContext().createBuffer(
                    currentAudioBuffer.numberOfChannels,
                    trimmedLength,
                    sampleRate
                );
                
                // Copy trimmed audio data
                for (let channel = 0; channel < currentAudioBuffer.numberOfChannels; channel++) {
                    const originalData = currentAudioBuffer.getChannelData(channel);
                    const trimmedData = trimmedBuffer.getChannelData(channel);
                    
                    for (let i = 0; i < trimmedLength; i++) {
                        const sourceIndex = startSample + i;
                        trimmedData[i] = sourceIndex < originalData.length ? originalData[sourceIndex] : 0;
                    }
                    
                    // Debug: Check first few samples to verify silence/padding
                    if (channel === 0) {
                        const firstSamples = [];
                        const sampleCheckCount = Math.min(100, trimmedLength);
                        for (let i = 0; i < sampleCheckCount; i++) {
                            firstSamples.push(Math.abs(trimmedData[i]).toFixed(6));
                        }
                        addResult(`First ${sampleCheckCount} samples: ${firstSamples.slice(0, 10).join(', ')}...`);
                        addResult(`Max amplitude in first 100 samples: ${Math.max(...firstSamples.map(s => parseFloat(s))).toFixed(6)}`);
                        
                        // Check if we have actual silence at the start
                        const silenceThreshold = 0.001;
                        let silentSamples = 0;
                        for (let i = 0; i < sampleCheckCount; i++) {
                            if (Math.abs(trimmedData[i]) < silenceThreshold) {
                                silentSamples++;
                            } else {
                                break;
                            }
                        }
                        addResult(`Silent samples at start: ${silentSamples}/${sampleCheckCount} (${(silentSamples / sampleRate * 1000).toFixed(1)}ms)`);
                        
                        // Check what the original audio looks like at the trim start point
                        const originalStartSample = startSample;
                        const originalSamples = [];
                        for (let i = Math.max(0, originalStartSample - 50); i < originalStartSample + 50; i++) {
                            if (i < originalData.length) {
                                originalSamples.push(Math.abs(originalData[i]).toFixed(6));
                            }
                        }
                        addResult(`Original audio around trim start (¬±50 samples from ${originalStartSample}):`);
                        addResult(`  Samples: ${originalSamples.slice(0, 10).join(', ')}...`);
                        
                        // Check if there's actual silence earlier in the file
                        let foundSilence = false;
                        let silenceStart = -1;
                        for (let i = 0; i < Math.min(originalStartSample, originalData.length); i++) {
                            if (Math.abs(originalData[i]) < silenceThreshold) {
                                if (!foundSilence) {
                                    silenceStart = i;
                                    foundSilence = true;
                                }
                            } else {
                                if (foundSilence && (i - silenceStart) > sampleRate * 0.01) { // At least 10ms of silence
                                    addResult(`Found earlier silence at sample ${silenceStart} (${(silenceStart / sampleRate).toFixed(3)}s)`);
                                    break;
                                }
                                foundSilence = false;
                            }
                        }
                        if (!foundSilence) {
                            addResult(`No significant silence found before current trim point`);
                        }
                    }
                }
                
                // Clean up previous trimmed URL if it exists
                if (currentTrimmedUrl) {
                    URL.revokeObjectURL(currentTrimmedUrl);
                    addResult('Cleaned up previous trimmed audio blob URL');
                }
                
                // Convert to blob and create preview
                const trimmedBlob = await audioBufferToBlob(trimmedBuffer);
                currentTrimmedUrl = URL.createObjectURL(trimmedBlob);
                const trimmedUrl = currentTrimmedUrl;
                
                // Create trimmed audio spectrogram
                await createTrimmedSpectrogram(trimmedUrl, trimStart, trimEnd);
                
                // Create audio preview element
                const previewContainer = document.createElement('div');
                previewContainer.innerHTML = `
                    <h4>üéµ Trimmed Audio Preview</h4>
                    <p>This is what the audio would sound like after VAD trimming:</p>
                    <audio controls style="width: 100%; margin: 10px 0;">
                        <source src="${trimmedUrl}" type="audio/wav">
                    </audio>
                    <div style="font-size: 14px; margin-top: 10px;">
                        <strong>Timing Details:</strong><br>
                        ‚Ä¢ Start padding: ${(earliestStart - trimStart).toFixed(3)}s<br>
                        ‚Ä¢ End padding: ${(trimEnd - latestEnd).toFixed(3)}s<br>
                        ‚Ä¢ Size reduction: ${((currentAudioBuffer.duration - (trimEnd - trimStart)) / currentAudioBuffer.duration * 100).toFixed(1)}%<br>
                        ‚Ä¢ Original: ${currentAudioBuffer.duration.toFixed(3)}s ‚Üí Trimmed: ${(trimEnd - trimStart).toFixed(3)}s
                    </div>
                `;
                
                // Add to audio section
                const audioSection = document.querySelector('.audio-section');
                
                // Remove existing preview if any
                const existingPreview = audioSection.querySelector('.trimmed-preview');
                if (existingPreview) {
                    existingPreview.remove();
                }
                
                previewContainer.className = 'trimmed-preview';
                previewContainer.style.cssText = `
                    margin: 20px 0;
                    padding: 15px;
                    background: #e8f5e8;
                    border: 2px solid #28a745;
                    border-radius: 8px;
                `;
                audioSection.appendChild(previewContainer);
                
                addResult('‚úÖ Trimmed audio preview and spectrogram created!', 'success');
                
            } catch (error) {
                addResult(`Error creating audio preview: ${error.message}`, 'error');
            }
        }

        // Create spectrogram for trimmed audio
        async function createTrimmedSpectrogram(trimmedUrl, originalTrimStart, originalTrimEnd) {
            try {
                addResult('Creating trimmed audio spectrogram...');
                
                // Destroy existing trimmed wavesurfer instance if it exists
                if (trimmedWavesurfer) {
                    try {
                        trimmedWavesurfer.destroy();
                        addResult('Cleaned up previous trimmed spectrogram instance');
                    } catch (destroyError) {
                        console.warn('Error destroying previous trimmed wavesurfer:', destroyError);
                    }
                    trimmedWavesurfer = null;
                }
                
                // Show the trimmed spectrogram container
                const trimmedSpectrogramContainer = document.getElementById('trimmed-spectrogram');
                trimmedSpectrogramContainer.style.display = 'block';
                
                // Clear any existing content
                trimmedSpectrogramContainer.innerHTML = '';
                
                // Import WaveSurfer plugins
                const { default: WaveSurfer } = await import('https://unpkg.com/wavesurfer.js@7/dist/wavesurfer.esm.js');
                const { default: Spectrogram } = await import('https://unpkg.com/wavesurfer.js@7/dist/plugins/spectrogram.esm.js');
                
                // Create a new WaveSurfer instance for trimmed audio
                trimmedWavesurfer = WaveSurfer.create({
                    container: '#trimmed-spectrogram',
                    waveColor: '#28a745',
                    progressColor: '#155724',
                    height: 120,
                    normalize: true,
                    barWidth: 2,
                    barRadius: 3
                });
                
                // Add spectrogram plugin with proper error handling  
                try {
                    const trimmedSpectrogramPlugin = Spectrogram.create({
                        container: '#trimmed-spectrogram',
                        labels: true,
                        height: 120,
                        splitChannels: false,
                        fftSamples: 512,
                        windowFunc: 'hann'
                    });
                    
                    trimmedWavesurfer.registerPlugin(trimmedSpectrogramPlugin);
                } catch (spectrogramError) {
                    console.warn('Trimmed spectrogram plugin failed, continuing without spectrogram:', spectrogramError);
                }
                trimmedWavesurfer.load(trimmedUrl);
                
                trimmedWavesurfer.on('ready', () => {
                    addResult(`‚úÖ Trimmed spectrogram ready`, 'success');
                    
                    // Add overlay information
                    const overlayInfo = document.createElement('div');
                    overlayInfo.style.cssText = `
                        position: relative;
                        background: rgba(40, 167, 69, 0.1);
                        padding: 8px;
                        margin-top: 5px;
                        border-radius: 4px;
                        font-size: 12px;
                        color: #155724;
                    `;
                    overlayInfo.innerHTML = `
                        <strong>Trimmed Audio Spectrogram:</strong><br>
                        ‚Ä¢ Original range: ${originalTrimStart.toFixed(3)}s - ${originalTrimEnd.toFixed(3)}s<br>
                        ‚Ä¢ This shows what the final trimmed audio looks like<br>
                        ‚Ä¢ Compare with original spectrogram above to see what was removed
                    `;
                    
                    trimmedSpectrogramContainer.appendChild(overlayInfo);
                });
                
                trimmedWavesurfer.on('error', (error) => {
                    console.warn('Trimmed spectrogram error (non-critical):', error);
                    // Continue execution - spectrogram errors are not critical
                });
                
            } catch (error) {
                addResult(`Error creating trimmed spectrogram: ${error.message}`, 'error');
            }
        }

        // Convert AudioBuffer to WAV Blob
        async function audioBufferToBlob(audioBuffer) {
            const numberOfChannels = audioBuffer.numberOfChannels;
            const sampleRate = audioBuffer.sampleRate;
            const length = audioBuffer.length;
            const bytesPerSample = 2; // 16-bit PCM
            const blockAlign = numberOfChannels * bytesPerSample;
            const byteRate = sampleRate * blockAlign;
            const dataSize = length * blockAlign;
            const bufferSize = 44 + dataSize;
            
            const arrayBuffer = new ArrayBuffer(bufferSize);
            const view = new DataView(arrayBuffer);
            
            // Write WAV header
            const writeString = (offset, string) => {
                for (let i = 0; i < string.length; i++) {
                    view.setUint8(offset + i, string.charCodeAt(i));
                }
            };
            
            writeString(0, 'RIFF');
            view.setUint32(4, bufferSize - 8, true);
            writeString(8, 'WAVE');
            writeString(12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true);
            view.setUint16(22, numberOfChannels, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, byteRate, true);
            view.setUint16(32, blockAlign, true);
            view.setUint16(34, 16, true);
            writeString(36, 'data');
            view.setUint32(40, dataSize, true);
            
            // Convert and write audio samples
            let offset = 44;
            for (let i = 0; i < length; i++) {
                for (let channel = 0; channel < numberOfChannels; channel++) {
                    const sample = Math.max(-1, Math.min(1, audioBuffer.getChannelData(channel)[i]));
                    view.setInt16(offset, sample * 0x7FFF, true);
                    offset += 2;
                }
            }
            
            return new Blob([arrayBuffer], { type: 'audio/wav' });
        }

        // Make essential functions available globally
        window.visualizeAudio = visualizeAudio;
        window.testSimplifiedVAD = testSimplifiedVAD;
        window.runCustomVAD = runCustomVAD;
        window.resetToDefaults = resetToDefaults;
        window.loadPreset = loadPreset;

        // // Add global error handlers for spectrogram errors
        // window.addEventListener('unhandledrejection', function(event) {
        //     if (event.reason && event.reason.message && event.reason.message.includes('length')) {
        //         console.warn('Suppressed spectrogram error (non-critical):', event.reason.message);
        //         event.preventDefault(); // Prevent the error from showing in console
        //         addResult('Note: Spectrogram visualization error suppressed - VAD processing continues normally', 'warning');
        //     }
        // });

        // window.addEventListener('error', function(event) {
        //     if (event.message && (event.message.includes('drawSpectrogram') || event.message.includes('length'))) {
        //         console.warn('Suppressed spectrogram error (non-critical):', event.message);
        //         event.preventDefault(); // Prevent the error from showing in console
        //         addResult('Note: Spectrogram error suppressed - functionality continues', 'warning');
        //         return true; // Prevent default error handling
        //     }
        // });

        // Initialize sliders and auto-run
        document.addEventListener('DOMContentLoaded', async () => {
            // Suppress ONNX runtime warnings
            try {
                if (typeof ort !== 'undefined' && ort.env) {
                    ort.env.logLevel = 'error';
                    console.log('ONNX log level set to error-only');
                }
            } catch (e) {
                console.log('Could not set ONNX log level:', e.message);
            }
            
            addResult('üéõÔ∏è VAD Tuner Ready', 'success');
            addResult('Auto-loading audio and running simplified VAD documentation pattern...', 'info');
            
            // Set up slider event listeners
            ['positiveSpeechThreshold', 'negativeSpeechThreshold', 'minSpeechFrames', 'redemptionFrames', 'padding'].forEach(id => {
                const input = document.getElementById(id);
                input.addEventListener('input', updateDisplayValues);
            });
            
            // Initialize display values
            updateDisplayValues();
            
            // Wait for libraries to load, then auto-run
            setTimeout(async () => {
                try {
                    // Load visualization first
                    await visualizeAudio();
                    
                    // Wait for waveform to be ready, then run simplified VAD
                    setTimeout(async () => {
                        await testSimplifiedVAD();
                    }, 2000);
                } catch (error) {
                    addResult(`Auto-run error: ${error.message}`, 'error');
                }
            }, 1000);
        });
    </script>
</body>
</html>
